Nig
nog
rig
rod
r
r <- 4
print rapply
print r
r
r[0]
r[1]
r <- 3
knitr::opts_chunk$set(echo = TRUE)
library(tm)
install.packages(c("tm", "tidytext", "tidyverse", "DT"))
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/cleaned_hm.csv'
hm_data <- read_csv(urlfile)
corpus <- VCorpus(VectorSource(hm_data$cleaned_hm))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, character(0))%>%
tm_map(stripWhitespace)
stemmed <- tm_map(corpus, stemDocument) %>%
tidy() %>%
select(text)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
data("stop_words")
word <- c("happy","ago","yesterday","lot","today","months","month",
"happier","happiest","last","week","past")
stop_words <- stop_words %>%
bind_rows(mutate(tibble(word), lexicon = "updated"))
completed <- stemmed %>%
mutate(id = row_number()) %>%
unnest_tokens(stems, text) %>%
bind_cols(dict) %>%
anti_join(stop_words, by = c("dictionary" = "word"))
completed <- completed %>%
group_by(stems) %>%
count(dictionary) %>%
mutate(word = dictionary[which.max(n)]) %>%
ungroup() %>%
select(stems, word) %>%
distinct() %>%
right_join(completed) %>%
select(-stems)
completed <- completed %>%
group_by(id) %>%
summarise(text = str_c(word, collapse = " ")) %>%
ungroup()
hm_data <- hm_data %>%
mutate(id = row_number()) %>%
inner_join(completed)
datatable(hm_data)
write_csv(hm_data, "../output/processed_moments.csv")
runApp(getwd())
install.packages("shiny")
shiny::runApp('Downloads/wk4-Shiny_tutorial')
runApp('Downloads/wk4-Shiny_tutorial')
runApp('Downloads/wk4-Shiny_tutorial')
shiny::runApp('Documents/GitHub/Spr2017-proj2-grp2/app')
install.packages(leaflet)
install.packages("leaflet")
runApp('Documents/GitHub/Spr2017-proj2-grp2/app')
runApp('Documents/GitHub/Spr2017-proj2-grp2/app')
runApp('Documents/GitHub/Spr2017-proj2-grp2/app')
runApp('Documents/GitHub/Spr2017-proj2-grp2/app')
runApp('Documents/GitHub/Spr2017-proj2-grp2/app')
shiny::runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
?frame_data
?frame
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
count_seperated.RData
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
packages.used=c("rgeos", "sp", "rgdal",
"leaflet", "htmlwidgets", "shiny",
"ggplot2", "dplyr", "data.table","DT", "readr")
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
install.packages("readr")
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
shiny::runApp('Documents/GitHub/Spring2019-Proj2-grp11/app')
data = read.csv('../data/AirportData/JFK_reduced.csv')
pwd
wksp
setwd("~/Documents/GitHub/Spring2019-Proj2-grp11/lib")
data = read.csv('../data/AirportData/JFK_reduced.csv')
data = data %>% subset(select = c('pickup_longitude', 'pickup_latitude', 'business_day', 'pickup_hour', 'farePerDistance'))
# data$WWH = ifelse(data$weekend, 2, 1 + 2 * !data$business_day)
data$WWH = ifelse(data$business_day, 1, 2)
# data$WWH = ifelse(data$weekend, 2, 1 + 2 * !data$business_day)
data$WWH = ifelse(data$business_day == "True", 1, 2)
count_result = array(dim = c(195,24,2))
FPD_result = array(dim = c(195,24,2))
load('output/myShape1.RData')
ls
getws
getwd
wd
getwd
getwd()
setwd("/Users/nelsonlin/Documents/GitHub/Spring2019-Proj2-grp11")
load('output/myShape1.RData')
subdat<-spTransform(myShape1, CRS("+init=epsg:4326"))
count_rank = rank(subdat@data$NTACode)
for (j in 1:2){
for (h in 1:24){
data.sel = data %>% subset(pickup_hour == h - 1 & WWH == j)
dat = data.frame(Longitude = data.sel$Pickup_longitude, Latitude = data.sel$Pickup_latitude)
coordinates(dat) <- ~ Longitude + Latitude
proj4string(dat) <- CRS("+proj=longlat")
dat <- spTransform(dat, proj4string(myShape1))
r = over(dat, myShape1)
r = r %>% subset(select = c('NTACode')) %>% cbind(data.sel)
count = table(r$NTACode)[count_rank]
FPD = tapply(r$farePerDistance, r$NTACode, mean)
count_result[,h,j] = as.vector(count)
FPD_result[,h,j] = as.vector(FPD)
}
}
for (j in 1:2){
for (h in 1:24){
data.sel = data %>% subset(pickup_hour == h - 1 & WWH == j)
dat = data.frame(Longitude = data.sel$pickup_longitude, Latitude = data.sel$pickup_latitude)
coordinates(dat) <- ~ Longitude + Latitude
proj4string(dat) <- CRS("+proj=longlat")
dat <- spTransform(dat, proj4string(myShape1))
r = over(dat, myShape1)
r = r %>% subset(select = c('NTACode')) %>% cbind(data.sel)
count = table(r$NTACode)[count_rank]
FPD = tapply(r$farePerDistance, r$NTACode, mean)
count_result[,h,j] = as.vector(count)
FPD_result[,h,j] = as.vector(FPD)
}
}
save(count_result, file = 'output/JFK_count_seperated.RData')
save(FPD_result, file = 'output/JFK_FPD_seperated.RData')
data = read.csv('/data/AirportData/NWK_reduced.csv')
data = read.csv('data/AirportData/NWK_reduced.csv')
data = data %>% subset(select = c('pickup_longitude', 'pickup_latitude', 'business_day', 'pickup_hour', 'farePerDistance'))
# data$WWH = ifelse(data$weekend, 2, 1 + 2 * !data$business_day)
data$WWH = ifelse(data$business_day == "True", 1, 2)
count_result = array(dim = c(195,24,2))
FPD_result = array(dim = c(195,24,2))
load('output/myShape1.RData')
subdat<-spTransform(myShape1, CRS("+init=epsg:4326"))
count_rank = rank(subdat@data$NTACode)
for (j in 1:2){
for (h in 1:24){
data.sel = data %>% subset(pickup_hour == h - 1 & WWH == j)
dat = data.frame(Longitude = data.sel$pickup_longitude, Latitude = data.sel$pickup_latitude)
coordinates(dat) <- ~ Longitude + Latitude
proj4string(dat) <- CRS("+proj=longlat")
dat <- spTransform(dat, proj4string(myShape1))
r = over(dat, myShape1)
r = r %>% subset(select = c('NTACode')) %>% cbind(data.sel)
count = table(r$NTACode)[count_rank]
FPD = tapply(r$farePerDistance, r$NTACode, mean)
count_result[,h,j] = as.vector(count)
FPD_result[,h,j] = as.vector(FPD)
}
}
save(count_result, file = 'output/NWK_count_seperated.RData')
save(FPD_result, file = 'output/NWK_FPD_seperated.RData')
data = read.csv('data/AirportData/LGA_reduced.csv')
data = data %>% subset(select = c('pickup_longitude', 'pickup_latitude', 'business_day', 'pickup_hour', 'farePerDistance'))
# data$WWH = ifelse(data$weekend, 2, 1 + 2 * !data$business_day)
data$WWH = ifelse(data$business_day == "True", 1, 2)
count_result = array(dim = c(195,24,2))
FPD_result = array(dim = c(195,24,2))
load('output/myShape1.RData')
subdat<-spTransform(myShape1, CRS("+init=epsg:4326"))
count_rank = rank(subdat@data$NTACode)
for (j in 1:2){
for (h in 1:24){
data.sel = data %>% subset(pickup_hour == h - 1 & WWH == j)
dat = data.frame(Longitude = data.sel$pickup_longitude, Latitude = data.sel$pickup_latitude)
coordinates(dat) <- ~ Longitude + Latitude
proj4string(dat) <- CRS("+proj=longlat")
dat <- spTransform(dat, proj4string(myShape1))
r = over(dat, myShape1)
r = r %>% subset(select = c('NTACode')) %>% cbind(data.sel)
count = table(r$NTACode)[count_rank]
FPD = tapply(r$farePerDistance, r$NTACode, mean)
count_result[,h,j] = as.vector(count)
FPD_result[,h,j] = as.vector(FPD)
}
}
save(count_result, file = 'output/LGA_count_seperated.RData')
save(FPD_result, file = 'output/LGA_FPD_seperated.RData')
data = read.csv('data/AirportData/LGA_reduced.csv')
data = data %>% subset(select = c('pickup_longitude', 'pickup_latitude', 'business_day', 'pickup_hour', 'farePerDistance'))
# data$WWH = ifelse(data$weekend, 2, 1 + 2 * !data$business_day)
data$WWH = ifelse(data$business_day == "True", 1, 2)
LGA_count_result = array(dim = c(195,24,2))
LGA_FPD_result = array(dim = c(195,24,2))
load('output/myShape1.RData')
subdat<-spTransform(myShape1, CRS("+init=epsg:4326"))
count_rank = rank(subdat@data$NTACode)
for (j in 1:2){
for (h in 1:24){
data.sel = data %>% subset(pickup_hour == h - 1 & WWH == j)
dat = data.frame(Longitude = data.sel$pickup_longitude, Latitude = data.sel$pickup_latitude)
coordinates(dat) <- ~ Longitude + Latitude
proj4string(dat) <- CRS("+proj=longlat")
dat <- spTransform(dat, proj4string(myShape1))
r = over(dat, myShape1)
r = r %>% subset(select = c('NTACode')) %>% cbind(data.sel)
count = table(r$NTACode)[count_rank]
FPD = tapply(r$farePerDistance, r$NTACode, mean)
LGA_count_result[,h,j] = as.vector(count)
LGA_FPD_result[,h,j] = as.vector(FPD)
}
}
save(LGA_count_result, file = 'output/LGA_count_seperated.RData')
save(LGA_FPD_result, file = 'output/LGA_FPD_seperated.RData')
data = read.csv('data/AirportData/NWK_reduced.csv')
data = data %>% subset(select = c('pickup_longitude', 'pickup_latitude', 'business_day', 'pickup_hour', 'farePerDistance'))
# data$WWH = ifelse(data$weekend, 2, 1 + 2 * !data$business_day)
data$WWH = ifelse(data$business_day == "True", 1, 2)
NWK_count_result = array(dim = c(195,24,2))
NWK_FPD_result = array(dim = c(195,24,2))
load('output/myShape1.RData')
subdat<-spTransform(myShape1, CRS("+init=epsg:4326"))
count_rank = rank(subdat@data$NTACode)
for (j in 1:2){
for (h in 1:24){
data.sel = data %>% subset(pickup_hour == h - 1 & WWH == j)
dat = data.frame(Longitude = data.sel$pickup_longitude, Latitude = data.sel$pickup_latitude)
coordinates(dat) <- ~ Longitude + Latitude
proj4string(dat) <- CRS("+proj=longlat")
dat <- spTransform(dat, proj4string(myShape1))
r = over(dat, myShape1)
r = r %>% subset(select = c('NTACode')) %>% cbind(data.sel)
count = table(r$NTACode)[count_rank]
FPD = tapply(r$farePerDistance, r$NTACode, mean)
NWK_count_result[,h,j] = as.vector(count)
NWK_FPD_result[,h,j] = as.vector(FPD)
}
}
save(NWK_count_result, file = 'output/LGA_count_seperated.RData')
save(NWK_FPD_result, file = 'output/LGA_FPD_seperated.RData')
save(NWK_count_result, file = 'output/NWK_count_seperated.RData')
save(NWK_FPD_result, file = 'output/NWK_FPD_seperated.RData')
data = read.csv('data/AirportData/LGA_reduced.csv')
data = data %>% subset(select = c('pickup_longitude', 'pickup_latitude', 'business_day', 'pickup_hour', 'farePerDistance'))
# data$WWH = ifelse(data$weekend, 2, 1 + 2 * !data$business_day)
data$WWH = ifelse(data$business_day == "True", 1, 2)
LGA_count_result = array(dim = c(195,24,2))
LGA_FPD_result = array(dim = c(195,24,2))
load('output/myShape1.RData')
subdat<-spTransform(myShape1, CRS("+init=epsg:4326"))
count_rank = rank(subdat@data$NTACode)
for (j in 1:2){
for (h in 1:24){
data.sel = data %>% subset(pickup_hour == h - 1 & WWH == j)
dat = data.frame(Longitude = data.sel$pickup_longitude, Latitude = data.sel$pickup_latitude)
coordinates(dat) <- ~ Longitude + Latitude
proj4string(dat) <- CRS("+proj=longlat")
dat <- spTransform(dat, proj4string(myShape1))
r = over(dat, myShape1)
r = r %>% subset(select = c('NTACode')) %>% cbind(data.sel)
count = table(r$NTACode)[count_rank]
FPD = tapply(r$farePerDistance, r$NTACode, mean)
LGA_count_result[,h,j] = as.vector(count)
LGA_FPD_result[,h,j] = as.vector(FPD)
}
}
save(LGA_count_result, file = 'output/LGA_count_seperated.RData')
save(LGA_FPD_result, file = 'output/LGA_FPD_seperated.RData')
data = read.csv('data/AirportData/JFK_reduced.csv')
data = data %>% subset(select = c('pickup_longitude', 'pickup_latitude', 'business_day', 'pickup_hour', 'farePerDistance'))
# data$WWH = ifelse(data$weekend, 2, 1 + 2 * !data$business_day)
data$WWH = ifelse(data$business_day == "True", 1, 2)
JFK_count_result = array(dim = c(195,24,2))
JFK_FPD_result = array(dim = c(195,24,2))
load('output/myShape1.RData')
subdat<-spTransform(myShape1, CRS("+init=epsg:4326"))
count_rank = rank(subdat@data$NTACode)
for (j in 1:2){
for (h in 1:24){
data.sel = data %>% subset(pickup_hour == h - 1 & WWH == j)
dat = data.frame(Longitude = data.sel$pickup_longitude, Latitude = data.sel$pickup_latitude)
coordinates(dat) <- ~ Longitude + Latitude
proj4string(dat) <- CRS("+proj=longlat")
dat <- spTransform(dat, proj4string(myShape1))
r = over(dat, myShape1)
r = r %>% subset(select = c('NTACode')) %>% cbind(data.sel)
count = table(r$NTACode)[count_rank]
FPD = tapply(r$farePerDistance, r$NTACode, mean)
JFK_count_result[,h,j] = as.vector(count)
JFK_FPD_result[,h,j] = as.vector(FPD)
}
}
save(JFK_count_result, file = 'output/JFK_count_seperated.RData')
save(JFK_FPD_result, file = 'output/JFK_FPD_seperated.RData')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
count_resultNTA = count_result1[which(rownames(count_result) == rtest$NTACode),,]
FPD_result1 <- JFK_count_result
source('~/Documents/GitHub/Spring2019-Proj2-grp11/lib/Test.R')
source('~/Documents/GitHub/Spring2019-Proj2-grp11/lib/Test.R')
getwd()
source('~/Documents/GitHub/Spring2019-Proj2-grp11/lib/Test.R')
runApp('app')
source('~/Documents/GitHub/Spring2019-Proj2-grp11/lib/Test.R')
dattest = data.frame(Longitude = -73.99155, Latitude = 40.76702)
library(rgeos)
library(sp)
library(rgdal)
library(leaflet)
library(htmlwidgets)
library(shiny)
library(ggplot2)
library(dplyr)
library(data.table)
library(readr)
setwd("/Users/nelsonlin/Documents/GitHub/Spring2019-Proj2-grp11")
load('output/myShape1.RData')
subdat<-spTransform(myShape1, CRS("+init=epsg:4326"))
# load airport traffic data
load('output/RSummarized/JFK_count_seperated.RData')
load('output/RSummarized/JFK_FPD_seperated.RData')
load('output/RSummarized/NWK_count_seperated.RData')
load('output/RSummarized/NWK_FPD_seperated.RData')
load('output/RSummarized/LGA_count_seperated.RData')
load('output/RSummarized/LGA_FPD_seperated.RData')
# load interactive data
load('output/count_seperated.RData')
load('output/FPD_seperated.RData')
# names of each borough. subdat is transformed shape1 file
rownames(count_result) = subdat@data$NTACode
count_result1 <- JFK_count_result
FPD_result1 <- JFK_count_result
dattest = data.frame(Longitude = -73.99155, Latitude = 40.76702)
coordinates(dattest) <- ~ Longitude + Latitude
proj4string(dattest) <- CRS("+proj=longlat")
dattest <- spTransform(dattest, proj4string(myShape1))
#rtest is to see which borough click falls in
rtest = over(dattest, myShape1)
count_resultNTA = count_result1[which(rownames(count_result) == rtest$NTACode),,]
count_resultNTA = apply(count_resultNTA, 1, sum)
index <- c(0:23)
dfcount_resultNTA <- data.frame(index, count_resultNTA)
ggplot(data=dfcount_resultNTA, aes(x=index, y=count_resultNTA)) + geom_bar(stat="identity") +
labs(x = "hour") + labs(y = "count per hour")+ggtitle("pick up count flow trend")+geom_smooth(formula = y~x)
runApp('app')
# names of each borough. subdat is transformed shape1 file
rownames(count_result) = subdat@data$NTACode
count_result1 <- JFK_count_result
FPD_result1 <- JFK_count_result
dattest = data.frame(Longitude = -73.83499, Latitude = 40.88029)
coordinates(dattest) <- ~ Longitude + Latitude
proj4string(dattest) <- CRS("+proj=longlat")
dattest <- spTransform(dattest, proj4string(myShape1))
#rtest is to see which borough click falls in
rtest = over(dattest, myShape1)
count_resultNTA = count_result1[which(rownames(count_result) == rtest$NTACode),,]
count_resultNTA = apply(count_resultNTA, 1, sum)
index <- c(0:23)
dfcount_resultNTA <- data.frame(index, count_resultNTA)
ggplot(data=dfcount_resultNTA, aes(x=index, y=count_resultNTA)) + geom_bar(stat="identity") +
labs(x = "hour") + labs(y = "count per hour")+ggtitle("pick up count flow trend")+geom_smooth(formula = y~x)
runApp('app')
runApp('app')
runApp('app')
library(rgeos)
library(sp)
library(rgdal)
library(leaflet)
library(htmlwidgets)
library(shiny)
library(ggplot2)
library(dplyr)
library(data.table)
library(readr)
setwd("/Users/nelsonlin/Documents/GitHub/Spring2019-Proj2-grp11")
load('output/myShape1.RData')
subdat<-spTransform(myShape1, CRS("+init=epsg:4326"))
# load airport traffic data
load('output/RSummarized/JFK_count_seperated.RData')
load('output/RSummarized/JFK_FPD_seperated.RData')
load('output/RSummarized/NWK_count_seperated.RData')
load('output/RSummarized/NWK_FPD_seperated.RData')
load('output/RSummarized/LGA_count_seperated.RData')
load('output/RSummarized/LGA_FPD_seperated.RData')
# load interactive data
load('output/count_seperated.RData')
load('output/FPD_seperated.RData')
# names of each borough. subdat is transformed shape1 file
rownames(count_result) = subdat@data$NTACode
count_result1 <- JFK_count_result
FPD_result1 <- JFK_count_result
dattest = data.frame(Longitude = -73.83499, Latitude = 40.88029)
coordinates(dattest) <- ~ Longitude + Latitude
proj4string(dattest) <- CRS("+proj=longlat")
dattest <- spTransform(dattest, proj4string(myShape1))
#rtest is to see which borough click falls in
rtest = over(dattest, myShape1)
count_resultNTA = count_result1[which(rownames(count_result) == rtest$NTACode),,]
count_resultNTA = apply(count_resultNTA, 1, sum)
print(count_resultNTA)
runApp('app')
library(rgeos)
library(sp)
library(rgdal)
library(leaflet)
library(htmlwidgets)
library(shiny)
library(ggplot2)
library(dplyr)
library(data.table)
library(readr)
setwd("/Users/nelsonlin/Documents/GitHub/Spring2019-Proj2-grp11")
load('output/myShape1.RData')
subdat<-spTransform(myShape1, CRS("+init=epsg:4326"))
# load airport traffic data
load('output/RSummarized/JFK_count_seperated.RData')
load('output/RSummarized/JFK_FPD_seperated.RData')
load('output/RSummarized/NWK_count_seperated.RData')
load('output/RSummarized/NWK_FPD_seperated.RData')
load('output/RSummarized/LGA_count_seperated.RData')
load('output/RSummarized/LGA_FPD_seperated.RData')
# load interactive data
load('output/count_seperated.RData')
load('output/FPD_seperated.RData')
# names of each borough. subdat is transformed shape1 file
rownames(count_result) = subdat@data$NTACode
count_result1 <- JFK_count_result
FPD_result1 <- JFK_count_result
dattest = data.frame(Longitude = -73.83499, Latitude = 40.88029)
coordinates(dattest) <- ~ Longitude + Latitude
proj4string(dattest) <- CRS("+proj=longlat")
dattest <- spTransform(dattest, proj4string(myShape1))
#rtest is to see which borough click falls in
rtest = over(dattest, myShape1)
count_resultNTA = count_result1[which(rownames(count_result) == rtest$NTACode),,]
print(count_resultNTA)
count_resultNTA = apply(count_resultNTA, 1, sum)
print(count_resultNTA)
index <- c(0:23)
dfcount_resultNTA <- data.frame(index, count_resultNTA)
ggplot(data=dfcount_resultNTA, aes(x=index, y=count_resultNTA)) + geom_bar(stat="identity") +
labs(x = "hour") + labs(y = "count per hour")+ggtitle("pick up count flow trend")+geom_smooth(formula = y~x)
print(rtest)
print(count_resultNTA)
print(count_resultNTA)
count_resultNTA = count_result1[which(rownames(count_result) == rtest$NTACode),,]
print(count_resultNTA)
count_resultNTA = count_result1[which(rownames(count_result) == rtest$NTACode),,]
print(count_resultNTA)
View(count_resultNTA)
runApp('app')
runApp('app')
